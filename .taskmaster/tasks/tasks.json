{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Setup Project Structure",
        "description": "Create the directory structure for the QR Tool project as specified in the PRD.",
        "details": "Create the following directory structure:\n```\nqr-tool/\n├── cache/\n│   ├── incoming-stored-items/\n│   ├── queued-stored-items/\n│   ├── processed-stored-items/\n│   ├── rejected-stored-items/\n│   ├── no-results-stored-items/\n│   ├── queued-study-moves/\n│   └── processed-study-moves/\n├── config.ps1\n├── FoDicomCmdlets/\n├── lib/\n├── qr-tool.ps1\n└── README.md\n```\nEnsure all directories have appropriate permissions for read/write operations. Initialize an empty README.md file that will be populated later.",
        "testStrategy": "Verify that all directories and files exist in the correct structure. Check that the directories have appropriate permissions for the application to read from and write to them.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Create Configuration File",
        "description": "Develop the config.ps1 file that contains all configurable parameters for the QR Tool.",
        "details": "Create the config.ps1 file with the following parameters:\n\n```powershell\n# DICOM Configuration\n$global:myAE = \"QR_TOOL\"  # The AET of this tool\n$global:qrServerAE = \"PACS_AE\"  # The AET of the PACS to query\n$global:qrServerHost = \"pacs.example.com\"  # The hostname or IP of the PACS\n$global:qrServerPort = 104  # The port number of the PACS\n$global:qrDestinationAE = \"DESTINATION_AE\"  # The AET where studies should be sent\n\n# Query Parameters\n$global:studyFindMonthsBack = 60  # Number of months back to search for studies\n$global:findAndMoveFixedModality = $null  # Set to a modality (e.g., \"CT\") or $null to use trigger file's modality\n\n# Operational Settings\n$global:sleepSeconds = 30  # Seconds to wait between processing cycles (0 to run once and exit)\n$global:mtimeThreshholdSeconds = 5  # Skip files modified less than this many seconds ago\n$global:largeFileThreshholdBytes = 1048576  # Files larger than this will have pixel data stripped\n$global:rejectByDeleting = $false  # If true, rejected files are deleted; if false, they're moved\n\n# Directory Configuration\n$scriptPath = Split-Path -Parent $MyInvocation.MyCommand.Path\n$global:cacheDirBasePath = Join-Path $scriptPath \"cache\"  # Base path for working directories\n$global:incomingStoredItemsDirPath = Join-Path $global:cacheDirBasePath \"incoming-stored-items\"\n$global:queuedStoredItemsDirPath = Join-Path $global:cacheDirBasePath \"queued-stored-items\"\n$global:processedStoredItemsDirPath = Join-Path $global:cacheDirBasePath \"processed-stored-items\"\n$global:rejectedStoredItemsDirPath = Join-Path $global:cacheDirBasePath \"rejected-stored-items\"\n$global:noResultsStoredItemsDirPath = Join-Path $global:cacheDirBasePath \"no-results-stored-items\"\n$global:queuedStudyMovesDirPath = Join-Path $global:cacheDirBasePath \"queued-study-moves\"\n$global:processedStudyMovesDirPath = Join-Path $global:cacheDirBasePath \"processed-study-moves\"\n```",
        "testStrategy": "Verify that the config.ps1 file exists and contains all the required parameters. Test loading the configuration file in a PowerShell session to ensure there are no syntax errors.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Develop Utility Functions",
        "description": "Create the utility-funs.ps1 file with common utility functions used across the application.",
        "details": "Create the lib/utility-funs.ps1 file with the following functions:\n\n```powershell\n# Function to create a log message with timestamp\nfunction Write-Log {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$Message,\n        [string]$Level = \"INFO\"\n    )\n    \n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    Write-Host \"[$timestamp] [$Level] $Message\"\n}\n\n# Function to ensure a directory exists\nfunction Ensure-DirectoryExists {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$Path\n    )\n    \n    if (-not (Test-Path -Path $Path)) {\n        New-Item -ItemType Directory -Path $Path -Force | Out-Null\n        Write-Log \"Created directory: $Path\"\n    }\n}\n\n# Function to generate a unique hash from DICOM tags\nfunction Get-DicomTagsHash {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$PatientName,\n        [Parameter(Mandatory=$true)]\n        [string]$PatientBirthDate,\n        [Parameter(Mandatory=$true)]\n        [string]$StudyDate\n    )\n    \n    $combinedString = \"$PatientName|$PatientBirthDate|$StudyDate\"\n    $bytes = [System.Text.Encoding]::UTF8.GetBytes($combinedString)\n    $hashAlgorithm = [System.Security.Cryptography.SHA256]::Create()\n    $hashBytes = $hashAlgorithm.ComputeHash($bytes)\n    $hash = [System.BitConverter]::ToString($hashBytes) -replace '-', ''\n    return $hash\n}\n\n# Function to check if a file is \"fresh\" (recently modified)\nfunction Is-FileFresh {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$FilePath\n    )\n    \n    $fileInfo = Get-Item $FilePath\n    $lastWriteTime = $fileInfo.LastWriteTime\n    $currentTime = Get-Date\n    $timeDifference = $currentTime - $lastWriteTime\n    \n    return ($timeDifference.TotalSeconds -lt $global:mtimeThreshholdSeconds)\n}\n\n# Function to check if a study has been processed before\nfunction Has-StudyBeenProcessed {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$StudyHash\n    )\n    \n    $processedFilePath = Join-Path $global:processedStoredItemsDirPath \"$StudyHash.processed\"\n    return (Test-Path $processedFilePath)\n}\n\n# Function to mark a study as processed\nfunction Mark-StudyAsProcessed {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$StudyHash\n    )\n    \n    $processedFilePath = Join-Path $global:processedStoredItemsDirPath \"$StudyHash.processed\"\n    New-Item -ItemType File -Path $processedFilePath -Force | Out-Null\n}\n```",
        "testStrategy": "Test each utility function individually with sample inputs to verify correct behavior. Ensure the functions handle edge cases appropriately, such as empty strings or non-existent paths.",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Develop DICOM Helper Functions",
        "description": "Create the dicom-funs.ps1 file with DICOM-related helper functions.",
        "details": "Create the lib/dicom-funs.ps1 file with the following functions:\n\n```powershell\n# Import the FoDicomCmdlets module\n$scriptPath = Split-Path -Parent $MyInvocation.MyCommand.Path\n$parentPath = Split-Path -Parent $scriptPath\n$cmdletsPath = Join-Path $parentPath \"FoDicomCmdlets\\bin\\Release\\net6.0\\FoDicomCmdlets.dll\"\nImport-Module $cmdletsPath\n\n# Function to extract DICOM tags from a file\nfunction Get-DicomTags {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$FilePath\n    )\n    \n    try {\n        $dicomFile = [Dicom.DicomFile]::Open($FilePath)\n        $dataset = $dicomFile.Dataset\n        \n        $tags = @{\n            \"PatientName\" = $dataset.GetString([Dicom.DicomTag]::PatientName)\n            \"PatientBirthDate\" = $dataset.GetString([Dicom.DicomTag]::PatientBirthDate)\n            \"StudyDate\" = $dataset.GetString([Dicom.DicomTag]::StudyDate)\n            \"StudyInstanceUID\" = $dataset.GetString([Dicom.DicomTag]::StudyInstanceUID)\n            \"Modality\" = $dataset.GetString([Dicom.DicomTag]::Modality)\n        }\n        \n        return $tags\n    }\n    catch {\n        Write-Log \"Error extracting DICOM tags from $FilePath: $_\" -Level \"ERROR\"\n        return $null\n    }\n}\n\n# Function to strip pixel data from a DICOM file\nfunction Strip-DicomPixelData {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$SourcePath,\n        [Parameter(Mandatory=$true)]\n        [string]$DestinationPath\n    )\n    \n    try {\n        $dicomFile = [Dicom.DicomFile]::Open($SourcePath)\n        $dataset = $dicomFile.Dataset\n        \n        # Remove pixel data if present\n        if ($dataset.Contains([Dicom.DicomTag]::PixelData)) {\n            $dataset.Remove([Dicom.DicomTag]::PixelData)\n        }\n        \n        # Save the modified file\n        $dicomFile.Save($DestinationPath)\n        return $true\n    }\n    catch {\n        Write-Log \"Error stripping pixel data from $SourcePath: $_\" -Level \"ERROR\"\n        return $false\n    }\n}\n\n# Function to query studies for a patient\nfunction Get-PatientStudies {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$PatientName,\n        [Parameter(Mandatory=$true)]\n        [string]$PatientBirthDate,\n        [string]$Modality = $null,\n        [int]$MonthsBack = $global:studyFindMonthsBack\n    )\n    \n    try {\n        $cutoffDate = (Get-Date).AddMonths(-$MonthsBack).ToString(\"yyyyMMdd\")\n        \n        $studies = Get-StudiesByPatientNameAndBirthDate `\n            -PatientName $PatientName `\n            -PatientBirthDate $PatientBirthDate `\n            -CallingAE $global:myAE `\n            -CalledAE $global:qrServerAE `\n            -RemoteHost $global:qrServerHost `\n            -RemotePort $global:qrServerPort `\n            -StudyDateFrom $cutoffDate `\n            -Modality $Modality\n        \n        return $studies\n    }\n    catch {\n        Write-Log \"Error querying studies for patient $PatientName: $_\" -Level \"ERROR\"\n        return @()\n    }\n}\n\n# Function to move a study by StudyInstanceUID\nfunction Move-Study {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$StudyInstanceUID\n    )\n    \n    try {\n        $result = Move-StudyByStudyInstanceUIDSync `\n            -StudyInstanceUID $StudyInstanceUID `\n            -CallingAE $global:myAE `\n            -CalledAE $global:qrServerAE `\n            -DestinationAE $global:qrDestinationAE `\n            -RemoteHost $global:qrServerHost `\n            -RemotePort $global:qrServerPort\n        \n        return $result\n    }\n    catch {\n        Write-Log \"Error moving study $StudyInstanceUID: $_\" -Level \"ERROR\"\n        return $false\n    }\n}\n```",
        "testStrategy": "Test each DICOM function with sample DICOM files to verify correct behavior. Ensure proper error handling when invalid DICOM files are provided or when network errors occur during DICOM operations.",
        "priority": "high",
        "dependencies": [
          1,
          2,
          3
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Implement Stage 1 - File Ingestion",
        "description": "Develop the stage-1.ps1 script for monitoring incoming DICOM files and preparing them for processing.",
        "details": "Create the lib/stage-1.ps1 file with the following implementation:\n\n```powershell\n# Import required modules\n. \"$PSScriptRoot\\utility-funs.ps1\"\n. \"$PSScriptRoot\\dicom-funs.ps1\"\n\nfunction Process-IncomingFiles {\n    Write-Log \"Starting Stage 1: File Ingestion\"\n    \n    # Ensure all required directories exist\n    Ensure-DirectoryExists $global:incomingStoredItemsDirPath\n    Ensure-DirectoryExists $global:queuedStoredItemsDirPath\n    Ensure-DirectoryExists $global:processedStoredItemsDirPath\n    Ensure-DirectoryExists $global:rejectedStoredItemsDirPath\n    \n    # Get all .dcm files in the incoming directory\n    $incomingFiles = Get-ChildItem -Path $global:incomingStoredItemsDirPath -Filter \"*.dcm\"\n    \n    Write-Log \"Found $($incomingFiles.Count) files in incoming directory\"\n    \n    foreach ($file in $incomingFiles) {\n        $filePath = $file.FullName\n        \n        # Skip files that are still being written\n        if (Is-FileFresh -FilePath $filePath) {\n            Write-Log \"Skipping fresh file: $($file.Name)\"\n            continue\n        }\n        \n        Write-Log \"Processing file: $($file.Name)\"\n        \n        # Extract DICOM tags\n        $tags = Get-DicomTags -FilePath $filePath\n        \n        if ($null -eq $tags) {\n            Write-Log \"Failed to extract DICOM tags from $($file.Name), rejecting file\" -Level \"ERROR\"\n            Move-Item -Path $filePath -Destination $global:rejectedStoredItemsDirPath\n            continue\n        }\n        \n        # Generate a unique hash for the study\n        $studyHash = Get-DicomTagsHash `\n            -PatientName $tags.PatientName `\n            -PatientBirthDate $tags.PatientBirthDate `\n            -StudyDate $tags.StudyDate\n        \n        # Check if this study has been processed before\n        if (Has-StudyBeenProcessed -StudyHash $studyHash) {\n            Write-Log \"Study has already been processed, rejecting file: $($file.Name)\"\n            \n            if ($global:rejectByDeleting) {\n                Remove-Item -Path $filePath -Force\n            } else {\n                Move-Item -Path $filePath -Destination $global:rejectedStoredItemsDirPath\n            }\n            \n            continue\n        }\n        \n        # Determine if we need to strip pixel data\n        $fileSize = (Get-Item $filePath).Length\n        $destinationPath = Join-Path $global:queuedStoredItemsDirPath \"$($file.Name)\"\n        \n        if ($fileSize -gt $global:largeFileThreshholdBytes) {\n            Write-Log \"File exceeds size threshold, stripping pixel data: $($file.Name)\"\n            $success = Strip-DicomPixelData -SourcePath $filePath -DestinationPath $destinationPath\n            \n            if (-not $success) {\n                Write-Log \"Failed to strip pixel data, moving original file\" -Level \"WARN\"\n                Move-Item -Path $filePath -Destination $destinationPath\n            } else {\n                # Original file is no longer needed\n                Remove-Item -Path $filePath -Force\n            }\n        } else {\n            # Move the file to the queued directory\n            Move-Item -Path $filePath -Destination $destinationPath\n        }\n        \n        Write-Log \"File queued for processing: $($file.Name)\"\n    }\n    \n    Write-Log \"Completed Stage 1: File Ingestion\"\n}\n```",
        "testStrategy": "Test the stage-1.ps1 script with sample DICOM files of various sizes. Verify that files are correctly moved to the appropriate directories based on their status (queued, rejected). Test the pixel data stripping functionality with large DICOM files.",
        "priority": "high",
        "dependencies": [
          1,
          2,
          3,
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement Stage 2 - Study Discovery",
        "description": "Develop the stage-2.ps1 script for querying the PACS for related studies based on patient information.",
        "details": "Create the lib/stage-2.ps1 file with the following implementation:\n\n```powershell\n# Import required modules\n. \"$PSScriptRoot\\utility-funs.ps1\"\n. \"$PSScriptRoot\\dicom-funs.ps1\"\n\nfunction Process-QueuedFiles {\n    Write-Log \"Starting Stage 2: Study Discovery\"\n    \n    # Ensure all required directories exist\n    Ensure-DirectoryExists $global:queuedStoredItemsDirPath\n    Ensure-DirectoryExists $global:processedStoredItemsDirPath\n    Ensure-DirectoryExists $global:noResultsStoredItemsDirPath\n    Ensure-DirectoryExists $global:queuedStudyMovesDirPath\n    \n    # Get all .dcm files in the queued directory\n    $queuedFiles = Get-ChildItem -Path $global:queuedStoredItemsDirPath -Filter \"*.dcm\"\n    \n    Write-Log \"Found $($queuedFiles.Count) files in queue\"\n    \n    foreach ($file in $queuedFiles) {\n        $filePath = $file.FullName\n        Write-Log \"Processing queued file: $($file.Name)\"\n        \n        # Extract DICOM tags\n        $tags = Get-DicomTags -FilePath $filePath\n        \n        if ($null -eq $tags) {\n            Write-Log \"Failed to extract DICOM tags from $($file.Name), moving to no-results\" -Level \"ERROR\"\n            Move-Item -Path $filePath -Destination $global:noResultsStoredItemsDirPath\n            continue\n        }\n        \n        # Generate a unique hash for the study\n        $studyHash = Get-DicomTagsHash `\n            -PatientName $tags.PatientName `\n            -PatientBirthDate $tags.PatientBirthDate `\n            -StudyDate $tags.StudyDate\n        \n        # Determine which modality to query for\n        $queryModality = $null\n        if ($null -ne $global:findAndMoveFixedModality) {\n            $queryModality = $global:findAndMoveFixedModality\n        } else {\n            $queryModality = $tags.Modality\n        }\n        \n        Write-Log \"Querying for studies with modality: $queryModality\"\n        \n        # Query for studies\n        $studies = Get-PatientStudies `\n            -PatientName $tags.PatientName `\n            -PatientBirthDate $tags.PatientBirthDate `\n            -Modality $queryModality `\n            -MonthsBack $global:studyFindMonthsBack\n        \n        if ($studies.Count -eq 0) {\n            Write-Log \"No studies found for patient, moving to no-results: $($file.Name)\"\n            Move-Item -Path $filePath -Destination $global:noResultsStoredItemsDirPath\n            continue\n        }\n        \n        Write-Log \"Found $($studies.Count) studies for patient\"\n        \n        # Create move request tickets for each study\n        $moveRequestsCreated = 0\n        \n        foreach ($study in $studies) {\n            $studyUID = $study.StudyInstanceUID\n            $ticketPath = Join-Path $global:queuedStudyMovesDirPath \"$studyUID.move-request\"\n            \n            # Check if this move request already exists\n            if (Test-Path $ticketPath) {\n                Write-Log \"Move request already exists for study: $studyUID\"\n                continue\n            }\n            \n            # Create the move request ticket\n            $study | ConvertTo-Json | Set-Content -Path $ticketPath\n            $moveRequestsCreated++\n            \n            Write-Log \"Created move request for study: $studyUID\"\n        }\n        \n        Write-Log \"Created $moveRequestsCreated move requests\"\n        \n        # Mark the study as processed\n        Mark-StudyAsProcessed -StudyHash $studyHash\n        \n        # Move the file to the processed directory\n        Move-Item -Path $filePath -Destination $global:processedStoredItemsDirPath\n        \n        Write-Log \"Completed processing file: $($file.Name)\"\n    }\n    \n    Write-Log \"Completed Stage 2: Study Discovery\"\n}\n```",
        "testStrategy": "Test the stage-2.ps1 script with sample DICOM files in the queued directory. Verify that the script correctly queries the PACS for related studies and creates move request tickets. Test with various configurations (fixed modality vs. same modality as trigger file).",
        "priority": "high",
        "dependencies": [
          1,
          2,
          3,
          4,
          5
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Implement Stage 3 - Study Retrieval",
        "description": "Develop the stage-3.ps1 script for processing move requests and retrieving studies from the PACS.",
        "details": "Create the lib/stage-3.ps1 file with the following implementation:\n\n```powershell\n# Import required modules\n. \"$PSScriptRoot\\utility-funs.ps1\"\n. \"$PSScriptRoot\\dicom-funs.ps1\"\n\nfunction Process-MoveRequests {\n    Write-Log \"Starting Stage 3: Study Retrieval\"\n    \n    # Ensure all required directories exist\n    Ensure-DirectoryExists $global:queuedStudyMovesDirPath\n    Ensure-DirectoryExists $global:processedStudyMovesDirPath\n    \n    # Get all .move-request files in the queued directory\n    $moveRequests = Get-ChildItem -Path $global:queuedStudyMovesDirPath -Filter \"*.move-request\"\n    \n    Write-Log \"Found $($moveRequests.Count) move requests in queue\"\n    \n    foreach ($request in $moveRequests) {\n        $requestPath = $request.FullName\n        $studyUID = $request.BaseName\n        \n        Write-Log \"Processing move request for study: $studyUID\"\n        \n        # Read the study information from the ticket\n        $studyInfo = Get-Content -Path $requestPath | ConvertFrom-Json\n        \n        # Issue the C-MOVE request\n        $success = Move-Study -StudyInstanceUID $studyUID\n        \n        if ($success) {\n            Write-Log \"Successfully moved study: $studyUID\"\n            \n            # Move the ticket to the processed directory\n            Move-Item -Path $requestPath -Destination $global:processedStudyMovesDirPath\n        } else {\n            Write-Log \"Failed to move study: $studyUID\" -Level \"ERROR\"\n            \n            # Leave the ticket in the queue to retry later\n            # Could implement a retry counter or failure handling mechanism here\n        }\n    }\n    \n    Write-Log \"Completed Stage 3: Study Retrieval\"\n}\n```",
        "testStrategy": "Test the stage-3.ps1 script with sample move request tickets. Verify that the script correctly issues C-MOVE requests to the PACS and moves the tickets to the processed directory upon success. Test error handling when C-MOVE operations fail.",
        "priority": "high",
        "dependencies": [
          1,
          2,
          3,
          4,
          6
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Develop FoDicomCmdlets C# Project",
        "description": "Create the C# project for custom DICOM PowerShell cmdlets that will be used by the PowerShell scripts.",
        "details": "Create the FoDicomCmdlets C# project with the following implementation:\n\n1. Create a new C# Class Library project targeting .NET 6.0\n2. Add the fo-dicom NuGet package as a dependency\n3. Implement the FoDicomCmdlets.cs file:\n\n```csharp\nusing System;\nusing System.Collections.Generic;\nusing System.Management.Automation;\nusing System.Threading.Tasks;\nusing Dicom;\nusing Dicom.Network;\n\nnamespace FoDicomCmdlets\n{\n    [Cmdlet(VerbsCommon.Get, \"StudiesByPatientNameAndBirthDate\")]\n    public class GetStudiesByPatientNameAndBirthDateCmdlet : PSCmdlet\n    {\n        [Parameter(Mandatory = true)]\n        public string PatientName { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public string PatientBirthDate { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public string CallingAE { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public string CalledAE { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public string RemoteHost { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public int RemotePort { get; set; }\n        \n        [Parameter(Mandatory = false)]\n        public string StudyDateFrom { get; set; }\n        \n        [Parameter(Mandatory = false)]\n        public string Modality { get; set; }\n        \n        protected override void ProcessRecord()\n        {\n            var studies = GetStudiesAsync().GetAwaiter().GetResult();\n            foreach (var study in studies)\n            {\n                WriteObject(study);\n            }\n        }\n        \n        private async Task<List<PSObject>> GetStudiesAsync()\n        {\n            var studies = new List<PSObject>();\n            \n            var client = DicomClientFactory.Create(RemoteHost, RemotePort, false, CallingAE, CalledAE);\n            \n            var request = new DicomCFindRequest(DicomQueryRetrieveLevel.Study);\n            \n            // Add query parameters\n            request.Dataset.Add(DicomTag.PatientName, PatientName);\n            request.Dataset.Add(DicomTag.PatientBirthDate, PatientBirthDate);\n            \n            if (!string.IsNullOrEmpty(StudyDateFrom))\n            {\n                request.Dataset.Add(DicomTag.StudyDate, $\"{StudyDateFrom}-\");\n            }\n            \n            if (!string.IsNullOrEmpty(Modality))\n            {\n                request.Dataset.Add(DicomTag.ModalitiesInStudy, Modality);\n            }\n            \n            // Add return fields\n            request.Dataset.Add(DicomTag.StudyInstanceUID, \"\");\n            request.Dataset.Add(DicomTag.StudyDate, \"\");\n            request.Dataset.Add(DicomTag.StudyTime, \"\");\n            request.Dataset.Add(DicomTag.StudyDescription, \"\");\n            request.Dataset.Add(DicomTag.ModalitiesInStudy, \"\");\n            \n            request.OnResponseReceived = (req, response) =>\n            {\n                var study = new PSObject();\n                study.Properties.Add(new PSNoteProperty(\"PatientName\", PatientName));\n                study.Properties.Add(new PSNoteProperty(\"PatientBirthDate\", PatientBirthDate));\n                study.Properties.Add(new PSNoteProperty(\"StudyInstanceUID\", response.Dataset.GetSingleValue<string>(DicomTag.StudyInstanceUID)));\n                study.Properties.Add(new PSNoteProperty(\"StudyDate\", response.Dataset.GetSingleValueOrDefault(DicomTag.StudyDate, \"\")));\n                study.Properties.Add(new PSNoteProperty(\"StudyTime\", response.Dataset.GetSingleValueOrDefault(DicomTag.StudyTime, \"\")));\n                study.Properties.Add(new PSNoteProperty(\"StudyDescription\", response.Dataset.GetSingleValueOrDefault(DicomTag.StudyDescription, \"\")));\n                study.Properties.Add(new PSNoteProperty(\"ModalitiesInStudy\", response.Dataset.GetSingleValueOrDefault(DicomTag.ModalitiesInStudy, \"\")));\n                \n                studies.Add(study);\n            };\n            \n            await client.AddRequestAsync(request);\n            await client.SendAsync();\n            \n            return studies;\n        }\n    }\n    \n    [Cmdlet(VerbsCommon.Move, \"StudyByStudyInstanceUIDSync\")]\n    public class MoveStudyByStudyInstanceUIDSyncCmdlet : PSCmdlet\n    {\n        [Parameter(Mandatory = true)]\n        public string StudyInstanceUID { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public string CallingAE { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public string CalledAE { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public string DestinationAE { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public string RemoteHost { get; set; }\n        \n        [Parameter(Mandatory = true)]\n        public int RemotePort { get; set; }\n        \n        protected override void ProcessRecord()\n        {\n            var success = MoveStudyAsync().GetAwaiter().GetResult();\n            WriteObject(success);\n        }\n        \n        private async Task<bool> MoveStudyAsync()\n        {\n            var client = DicomClientFactory.Create(RemoteHost, RemotePort, false, CallingAE, CalledAE);\n            \n            var request = new DicomCMoveRequest(DestinationAE, StudyInstanceUID);\n            \n            var success = true;\n            var completed = false;\n            \n            request.OnResponseReceived = (req, response) =>\n            {\n                if (response.Status != DicomStatus.Success && \n                    response.Status != DicomStatus.Pending)\n                {\n                    success = false;\n                }\n                \n                if (response.Status.State != DicomState.Pending)\n                {\n                    completed = true;\n                }\n            };\n            \n            await client.AddRequestAsync(request);\n            await client.SendAsync();\n            \n            // Wait for the operation to complete\n            while (!completed)\n            {\n                await Task.Delay(100);\n            }\n            \n            return success;\n        }\n    }\n}\n```\n\n4. Build the project in Release mode to generate the DLL file.",
        "testStrategy": "Build the FoDicomCmdlets project and verify that the DLL is generated correctly. Test the cmdlets by importing the module in PowerShell and executing sample commands to query for studies and move studies. Verify that the cmdlets handle errors appropriately.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Create Main QR Tool Script",
        "description": "Develop the main qr-tool.ps1 script that orchestrates the three stages of the workflow.",
        "details": "Create the qr-tool.ps1 file with the following implementation:\n\n```powershell\n# QR Tool - DICOM Study Pre-fetching Tool\n# Main script that orchestrates the three stages of the workflow\n\n# Import configuration\n. \"$PSScriptRoot\\config.ps1\"\n\n# Import stage scripts\n. \"$PSScriptRoot\\lib\\stage-1.ps1\"\n. \"$PSScriptRoot\\lib\\stage-2.ps1\"\n. \"$PSScriptRoot\\lib\\stage-3.ps1\"\n\n# Function to run a single cycle of the workflow\nfunction Run-WorkflowCycle {\n    Write-Host \"\\n===== Starting QR Tool Workflow Cycle at $(Get-Date) =====\"\n    \n    # Run Stage 1: File Ingestion\n    Process-IncomingFiles\n    \n    # Run Stage 2: Study Discovery\n    Process-QueuedFiles\n    \n    # Run Stage 3: Study Retrieval\n    Process-MoveRequests\n    \n    Write-Host \"===== Completed QR Tool Workflow Cycle at $(Get-Date) =====\\n\"\n}\n\n# Main execution logic\nWrite-Host \"Starting QR Tool...\"\n\n# Ensure all directories exist\nEnsure-DirectoryExists $global:cacheDirBasePath\nEnsure-DirectoryExists $global:incomingStoredItemsDirPath\nEnsure-DirectoryExists $global:queuedStoredItemsDirPath\nEnsure-DirectoryExists $global:processedStoredItemsDirPath\nEnsure-DirectoryExists $global:rejectedStoredItemsDirPath\nEnsure-DirectoryExists $global:noResultsStoredItemsDirPath\nEnsure-DirectoryExists $global:queuedStudyMovesDirPath\nEnsure-DirectoryExists $global:processedStudyMovesDirPath\n\n# Run once or in a loop based on configuration\nif ($global:sleepSeconds -eq 0) {\n    # Run once and exit\n    Write-Host \"Running in single-execution mode\"\n    Run-WorkflowCycle\n} else {\n    # Run in a loop with sleep between cycles\n    Write-Host \"Running in continuous mode with $global:sleepSeconds seconds sleep between cycles\"\n    \n    try {\n        while ($true) {\n            Run-WorkflowCycle\n            \n            Write-Host \"Sleeping for $global:sleepSeconds seconds...\"\n            Start-Sleep -Seconds $global:sleepSeconds\n        }\n    } catch {\n        Write-Host \"Error in main loop: $_\" -ForegroundColor Red\n    } finally {\n        Write-Host \"QR Tool stopped at $(Get-Date)\"\n    }\n}\n```",
        "testStrategy": "Test the qr-tool.ps1 script in both single-execution mode and continuous mode. Verify that it correctly orchestrates the three stages of the workflow and handles errors appropriately. Test the script's behavior when interrupted (e.g., with Ctrl+C).",
        "priority": "high",
        "dependencies": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Create Comprehensive README",
        "description": "Create a comprehensive README.md file with installation instructions, usage examples, and configuration details.",
        "details": "Create the README.md file with the following content:\n\n```markdown\n# QR Tool\n\nA PowerShell-based tool for automating DICOM study pre-fetching. It monitors an input directory for new DICOM files, and when a new file appears, it automatically queries a PACS for other studies belonging to the same patient, and then issues a move request to have those studies sent to a pre-configured destination.\n\n## Features\n\n* **Automatic Prefetching:** Monitors a directory for incoming DICOM files and triggers a prefetching workflow.\n* **Patient-Centric Query:** Identifies the patient from the incoming file and queries a PACS for related studies.\n* **Configurable Query Parameters:** Allows specifying a timeframe for the study search (e.g., last 60 months) and can be configured to query for a fixed modality or the same modality as the trigger file.\n* **Flexible Destination:** The destination Application Entity (AE) for the C-MOVE operation is configurable.\n* **Robust Workflow Management:** Uses a multi-stage process with dedicated directories for tracking the state of each task (queued, processed, rejected, no-results).\n* **Efficient Processing:** Avoids re-processing of already handled studies by keeping a history of processed files.\n* **Pixel Data Stripping:** Optionally strips pixel data from large DICOM files to save space, as only the header information is needed for the query.\n* **Looping Operation:** Can be configured to run continuously, with a configurable sleep interval between cycles.\n\n## Prerequisites\n\n* PowerShell 5.1 or later (PowerShell Core 6.0+ recommended)\n* .NET 6.0 SDK (for building the FoDicomCmdlets)\n* Visual Studio 2019 or later (for building the FoDicomCmdlets)\n\n## Installation\n\n1. Clone this repository:\n   ```\n   git clone https://github.com/yourusername/qr-tool.git\n   cd qr-tool\n   ```\n\n2. Build the FoDicomCmdlets:\n   * Open the `FoDicomCmdlets/FoDicomCmdlets.sln` solution in Visual Studio\n   * Build the solution in `Release` mode\n   * This will produce the `FoDicomCmdlets.dll` and download the required `Dicom.Core.dll` from `fo-dicom`\n\n3. Configure the tool:\n   * Edit `config.ps1` to match your environment (see Configuration section below)\n\n## Configuration\n\nAll configuration is done in the `config.ps1` file. The following parameters can be configured:\n\n### DICOM Configuration\n\n* `$global:myAE`: The Application Entity Title (AET) of this tool\n* `$global:qrServerAE`: The AET of the PACS to query\n* `$global:qrServerHost`: The hostname or IP address of the PACS\n* `$global:qrServerPort`: The port number of the PACS\n* `$global:qrDestinationAE`: The AET of the destination where the studies should be sent\n\n### Query Parameters\n\n* `$global:studyFindMonthsBack`: The number of months back to search for studies\n* `$global:findAndMoveFixedModality`: If set to a modality (e.g., \"CT\"), the tool will query for studies of that modality. If `$null`, it will query for studies with the same modality as the trigger file.\n\n### Operational Settings\n\n* `$global:sleepSeconds`: The number of seconds to wait between processing cycles. If set to 0, the script will run once and exit.\n* `$global:mtimeThreshholdSeconds`: A file in the incoming directory is considered \"fresh\" and will be skipped if its last modified time is less than this many seconds ago. This prevents processing of partially written files.\n* `$global:largeFileThreshholdBytes`: Files larger than this size (in bytes) will have their pixel data stripped in Stage 1.\n* `$global:rejectByDeleting`: If `$true`, rejected files will be deleted. If `$false`, they will be moved to the `rejected-stored-items` directory.\n\n## Usage\n\n1. Start the tool:\n   ```\n   ./qr-tool.ps1\n   ```\n\n2. Place DICOM files in the `cache/incoming-stored-items` directory to trigger the workflow.\n\n3. The tool will process the files according to the three-stage pipeline described below.\n\n## How It Works\n\nThe tool operates in a three-stage pipeline:\n\n1. **Stage 1: File Ingestion (`stage-1.ps1`)**\n   * Monitors the `incoming-stored-items` directory for new `.dcm` files.\n   * For each new file, it extracts `PatientName`, `PatientBirthDate`, and `StudyDate`.\n   * A unique hash is generated from these tags to identify the study.\n   * If the study has not been processed before, the file is moved to the `queued-stored-items` directory. If it's a large file, the pixel data may be stripped.\n   * If the study has already been processed, the incoming file is rejected (either by deleting it or moving it to the `rejected-stored-items` directory).\n\n2. **Stage 2: Study Discovery (`stage-2.ps1`)**\n   * Processes files in the `queued-stored-items` directory.\n   * For each file, it performs a C-FIND query against the configured PACS (`qrServerAE`) to find other studies for the same patient.\n   * The search can be limited by the `studyFindMonthsBack` parameter and can be configured to look for a specific modality using `findAndMoveFixedModality`.\n   * If studies are found, it creates a `.move-request` ticket for each study in the `queued-study-moves` directory. The ticket is named with the `StudyInstanceUID`.\n   * The original file from the queue is then moved to the `processed-stored-items` directory.\n   * If no studies are found, the file is moved to the `no-results-stored-items` directory.\n\n3. **Stage 3: Study Retrieval (`stage-3.ps1`)**\n   * Processes the `.move-request` tickets in the `queued-study-moves` directory.\n   * For each ticket, it issues a C-MOVE request to the PACS to send the corresponding study to the configured destination AE (`qrDestinationAE`).\n   * Upon successful completion of the C-MOVE, the ticket is moved to the `processed-study-moves` directory.\n\n## Troubleshooting\n\n* **Files not being processed:** Check that the files are valid DICOM files and that they have been in the incoming directory for longer than `mtimeThreshholdSeconds`.\n* **No studies found:** Verify that the PACS configuration is correct and that the patient information in the trigger file matches records in the PACS.\n* **C-MOVE failures:** Check that the destination AE is correctly configured and accessible from the PACS.\n\n## License\n\n[MIT License](LICENSE)\n```",
        "testStrategy": "Review the README.md file for completeness and accuracy. Ensure that it provides clear instructions for installation, configuration, and usage of the QR Tool. Verify that all features and operational details are correctly documented.",
        "priority": "medium",
        "dependencies": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Implement Error Handling and Logging",
        "description": "Enhance the scripts with comprehensive error handling and logging capabilities.",
        "details": "Enhance the error handling and logging in all scripts:\n\n1. Create a dedicated logging module in lib/logging.ps1:\n\n```powershell\n# Logging levels\n$global:LogLevels = @{\n    \"DEBUG\" = 0\n    \"INFO\" = 1\n    \"WARN\" = 2\n    \"ERROR\" = 3\n    \"FATAL\" = 4\n}\n\n# Current log level (default to INFO)\n$global:CurrentLogLevel = $global:LogLevels[\"INFO\"]\n\n# Log file path\n$global:LogFilePath = $null\n\n# Function to set the log level\nfunction Set-LogLevel {\n    param(\n        [Parameter(Mandatory=$true)]\n        [ValidateSet(\"DEBUG\", \"INFO\", \"WARN\", \"ERROR\", \"FATAL\")]\n        [string]$Level\n    )\n    \n    $global:CurrentLogLevel = $global:LogLevels[$Level]\n    Write-Log \"Log level set to $Level\" -Level \"INFO\"\n}\n\n# Function to set the log file path\nfunction Set-LogFile {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$Path\n    )\n    \n    $global:LogFilePath = $Path\n    \n    # Create the log file if it doesn't exist\n    if (-not (Test-Path -Path $Path)) {\n        New-Item -ItemType File -Path $Path -Force | Out-Null\n    }\n    \n    Write-Log \"Log file set to $Path\" -Level \"INFO\"\n}\n\n# Function to write a log message\nfunction Write-Log {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$Message,\n        \n        [Parameter(Mandatory=$false)]\n        [ValidateSet(\"DEBUG\", \"INFO\", \"WARN\", \"ERROR\", \"FATAL\")]\n        [string]$Level = \"INFO\",\n        \n        [Parameter(Mandatory=$false)]\n        [switch]$NoConsole\n    )\n    \n    # Check if the message should be logged based on the current log level\n    if ($global:LogLevels[$Level] -ge $global:CurrentLogLevel) {\n        $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n        $logMessage = \"[$timestamp] [$Level] $Message\"\n        \n        # Write to console if not suppressed\n        if (-not $NoConsole) {\n            $foregroundColor = switch ($Level) {\n                \"DEBUG\" { \"Gray\" }\n                \"INFO\" { \"White\" }\n                \"WARN\" { \"Yellow\" }\n                \"ERROR\" { \"Red\" }\n                \"FATAL\" { \"Red\" }\n                default { \"White\" }\n            }\n            \n            Write-Host $logMessage -ForegroundColor $foregroundColor\n        }\n        \n        # Write to log file if configured\n        if ($null -ne $global:LogFilePath) {\n            Add-Content -Path $global:LogFilePath -Value $logMessage\n        }\n    }\n}\n\n# Function to log an exception\nfunction Write-Exception {\n    param(\n        [Parameter(Mandatory=$true)]\n        [System.Exception]$Exception,\n        \n        [Parameter(Mandatory=$false)]\n        [string]$Message = \"An exception occurred\",\n        \n        [Parameter(Mandatory=$false)]\n        [ValidateSet(\"WARN\", \"ERROR\", \"FATAL\")]\n        [string]$Level = \"ERROR\"\n    )\n    \n    $exceptionMessage = \"$Message: $($Exception.Message)\"\n    Write-Log $exceptionMessage -Level $Level\n    \n    # Log stack trace at DEBUG level\n    Write-Log \"Stack Trace: $($Exception.StackTrace)\" -Level \"DEBUG\"\n    \n    # Log inner exception if present\n    if ($null -ne $Exception.InnerException) {\n        Write-Log \"Inner Exception: $($Exception.InnerException.Message)\" -Level $Level\n        Write-Log \"Inner Stack Trace: $($Exception.InnerException.StackTrace)\" -Level \"DEBUG\"\n    }\n}\n```\n\n2. Update the main qr-tool.ps1 script to initialize logging:\n\n```powershell\n# Import logging module\n. \"$PSScriptRoot\\lib\\logging.ps1\"\n\n# Initialize logging\n$logDir = Join-Path $global:cacheDirBasePath \"logs\"\nEnsure-DirectoryExists $logDir\n$logFile = Join-Path $logDir \"qr-tool-$(Get-Date -Format 'yyyyMMdd').log\"\nSet-LogFile -Path $logFile\n\n# Set log level from configuration (add to config.ps1: $global:logLevel = \"INFO\")\nif ($null -ne $global:logLevel) {\n    Set-LogLevel -Level $global:logLevel\n}\n```\n\n3. Update all scripts to use the enhanced logging and add try-catch blocks for error handling.\n\n4. Add a global error handler to the main script:\n\n```powershell\n# Global error handler\n$global:ErrorActionPreference = \"Stop\"\n\n# Error handling for the main script\ntry {\n    # Main script logic here\n} catch {\n    Write-Exception -Exception $_ -Message \"Unhandled exception in main script\"\n    exit 1\n}\n```",
        "testStrategy": "Test the logging functionality by running the QR Tool with different log levels. Verify that log messages are correctly written to both the console and the log file. Test error handling by deliberately introducing errors and verifying that they are caught and logged appropriately.",
        "priority": "medium",
        "dependencies": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Implement Performance Monitoring",
        "description": "Add performance monitoring capabilities to track processing times and throughput.",
        "details": "Create a performance monitoring module in lib/performance.ps1:\n\n```powershell\n# Import logging module\n. \"$PSScriptRoot\\logging.ps1\"\n\n# Performance metrics\n$global:PerformanceMetrics = @{}\n\n# Function to start a timer for a specific operation\nfunction Start-OperationTimer {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$OperationName\n    )\n    \n    $timer = [System.Diagnostics.Stopwatch]::StartNew()\n    $global:PerformanceMetrics[$OperationName] = @{\n        \"StartTime\" = Get-Date\n        \"Timer\" = $timer\n        \"ItemsProcessed\" = 0\n    }\n    \n    Write-Log \"Started operation: $OperationName\" -Level \"DEBUG\"\n}\n\n# Function to stop a timer and log the results\nfunction Stop-OperationTimer {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$OperationName,\n        \n        [Parameter(Mandatory=$false)]\n        [int]$ItemsProcessed = 0\n    )\n    \n    if ($global:PerformanceMetrics.ContainsKey($OperationName)) {\n        $metrics = $global:PerformanceMetrics[$OperationName]\n        $metrics.Timer.Stop()\n        \n        # Update items processed if provided\n        if ($ItemsProcessed -gt 0) {\n            $metrics.ItemsProcessed = $ItemsProcessed\n        }\n        \n        $elapsedMs = $metrics.Timer.ElapsedMilliseconds\n        $elapsedSec = $elapsedMs / 1000\n        \n        # Calculate items per second if items were processed\n        $itemsPerSecond = 0\n        if ($metrics.ItemsProcessed -gt 0 -and $elapsedSec -gt 0) {\n            $itemsPerSecond = $metrics.ItemsProcessed / $elapsedSec\n        }\n        \n        # Log the results\n        Write-Log \"Completed operation: $OperationName in $elapsedMs ms\" -Level \"INFO\"\n        \n        if ($metrics.ItemsProcessed -gt 0) {\n            Write-Log \"Processed $($metrics.ItemsProcessed) items at $([math]::Round($itemsPerSecond, 2)) items/sec\" -Level \"INFO\"\n        }\n        \n        # Remove the operation from the metrics dictionary\n        $global:PerformanceMetrics.Remove($OperationName)\n        \n        return @{\n            \"ElapsedMilliseconds\" = $elapsedMs\n            \"ItemsProcessed\" = $metrics.ItemsProcessed\n            \"ItemsPerSecond\" = $itemsPerSecond\n        }\n    } else {\n        Write-Log \"No timer found for operation: $OperationName\" -Level \"WARN\"\n        return $null\n    }\n}\n\n# Function to increment the items processed count for an operation\nfunction Increment-OperationItemsProcessed {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$OperationName,\n        \n        [Parameter(Mandatory=$false)]\n        [int]$IncrementBy = 1\n    )\n    \n    if ($global:PerformanceMetrics.ContainsKey($OperationName)) {\n        $global:PerformanceMetrics[$OperationName].ItemsProcessed += $IncrementBy\n    } else {\n        Write-Log \"No timer found for operation: $OperationName\" -Level \"WARN\"\n    }\n}\n```\n\nUpdate the stage scripts to use the performance monitoring:\n\n```powershell\n# In stage-1.ps1\nfunction Process-IncomingFiles {\n    Write-Log \"Starting Stage 1: File Ingestion\"\n    Start-OperationTimer -OperationName \"Stage1\"\n    \n    # ... existing code ...\n    \n    foreach ($file in $incomingFiles) {\n        # ... existing code ...\n        \n        # Increment processed items\n        Increment-OperationItemsProcessed -OperationName \"Stage1\"\n    }\n    \n    # Stop the timer and log results\n    Stop-OperationTimer -OperationName \"Stage1\" -ItemsProcessed $incomingFiles.Count\n    Write-Log \"Completed Stage 1: File Ingestion\"\n}\n```\n\nApply similar changes to stage-2.ps1 and stage-3.ps1.",
        "testStrategy": "Test the performance monitoring by running the QR Tool with sample DICOM files. Verify that performance metrics are correctly calculated and logged. Test with different numbers of files to ensure the metrics scale appropriately.",
        "priority": "low",
        "dependencies": [
          5,
          6,
          7,
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Implement Retry Mechanism for Failed Operations",
        "description": "Add a retry mechanism for failed DICOM operations to improve reliability.",
        "details": "Create a retry utility in lib/retry.ps1:\n\n```powershell\n# Import logging module\n. \"$PSScriptRoot\\logging.ps1\"\n\n# Function to execute an operation with retries\nfunction Invoke-WithRetry {\n    param(\n        [Parameter(Mandatory=$true)]\n        [scriptblock]$ScriptBlock,\n        \n        [Parameter(Mandatory=$false)]\n        [int]$MaxRetries = 3,\n        \n        [Parameter(Mandatory=$false)]\n        [int]$RetryDelayMs = 1000,\n        \n        [Parameter(Mandatory=$false)]\n        [scriptblock]$RetryCondition = { $false },\n        \n        [Parameter(Mandatory=$false)]\n        [string]$OperationName = \"Operation\"\n    )\n    \n    $retryCount = 0\n    $success = $false\n    $result = $null\n    \n    do {\n        try {\n            if ($retryCount -gt 0) {\n                Write-Log \"Retry $retryCount/$MaxRetries for $OperationName\" -Level \"INFO\"\n                Start-Sleep -Milliseconds $RetryDelayMs\n            }\n            \n            $result = & $ScriptBlock\n            $success = $true\n        } catch {\n            $retryCount++\n            $shouldRetry = ($retryCount -le $MaxRetries) -or (& $RetryCondition)\n            \n            if ($shouldRetry) {\n                Write-Log \"$OperationName failed, will retry ($retryCount/$MaxRetries): $($_.Exception.Message)\" -Level \"WARN\"\n            } else {\n                Write-Exception -Exception $_ -Message \"$OperationName failed after $retryCount retries\"\n                throw\n            }\n        }\n    } while (-not $success -and $retryCount -le $MaxRetries)\n    \n    return $result\n}\n```\n\nUpdate the DICOM operations in dicom-funs.ps1 to use the retry mechanism:\n\n```powershell\n# Import retry module\n. \"$PSScriptRoot\\retry.ps1\"\n\n# Function to query studies for a patient with retry\nfunction Get-PatientStudies {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$PatientName,\n        [Parameter(Mandatory=$true)]\n        [string]$PatientBirthDate,\n        [string]$Modality = $null,\n        [int]$MonthsBack = $global:studyFindMonthsBack\n    )\n    \n    $operationName = \"Query studies for patient $PatientName\"\n    \n    return Invoke-WithRetry -ScriptBlock {\n        $cutoffDate = (Get-Date).AddMonths(-$MonthsBack).ToString(\"yyyyMMdd\")\n        \n        $studies = Get-StudiesByPatientNameAndBirthDate `\n            -PatientName $PatientName `\n            -PatientBirthDate $PatientBirthDate `\n            -CallingAE $global:myAE `\n            -CalledAE $global:qrServerAE `\n            -RemoteHost $global:qrServerHost `\n            -RemotePort $global:qrServerPort `\n            -StudyDateFrom $cutoffDate `\n            -Modality $Modality\n        \n        return $studies\n    } -MaxRetries 3 -RetryDelayMs 2000 -OperationName $operationName\n}\n\n# Function to move a study by StudyInstanceUID with retry\nfunction Move-Study {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$StudyInstanceUID\n    )\n    \n    $operationName = \"Move study $StudyInstanceUID\"\n    \n    return Invoke-WithRetry -ScriptBlock {\n        $result = Move-StudyByStudyInstanceUIDSync `\n            -StudyInstanceUID $StudyInstanceUID `\n            -CallingAE $global:myAE `\n            -CalledAE $global:qrServerAE `\n            -DestinationAE $global:qrDestinationAE `\n            -RemoteHost $global:qrServerHost `\n            -RemotePort $global:qrServerPort\n        \n        if (-not $result) {\n            throw \"C-MOVE operation failed\"\n        }\n        \n        return $result\n    } -MaxRetries 3 -RetryDelayMs 5000 -OperationName $operationName\n}\n```",
        "testStrategy": "Test the retry mechanism by simulating network failures or DICOM operation failures. Verify that the operations are retried the correct number of times and that the appropriate error messages are logged. Test successful retries and permanent failures.",
        "priority": "medium",
        "dependencies": [
          4,
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement Study Deduplication",
        "description": "Add functionality to avoid requesting the same study multiple times.",
        "details": "Enhance the stage-2.ps1 script to implement study deduplication:\n\n```powershell\n# Function to check if a study move has already been requested\nfunction Has-StudyMoveBeenRequested {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$StudyInstanceUID\n    )\n    \n    $queuedPath = Join-Path $global:queuedStudyMovesDirPath \"$StudyInstanceUID.move-request\"\n    $processedPath = Join-Path $global:processedStudyMovesDirPath \"$StudyInstanceUID.move-request\"\n    \n    return (Test-Path $queuedPath) -or (Test-Path $processedPath)\n}\n\n# Update the Process-QueuedFiles function\nfunction Process-QueuedFiles {\n    # ... existing code ...\n    \n    foreach ($study in $studies) {\n        $studyUID = $study.StudyInstanceUID\n        \n        # Check if this study has already been requested\n        if (Has-StudyMoveBeenRequested -StudyInstanceUID $studyUID) {\n            Write-Log \"Study $studyUID has already been requested, skipping\"\n            continue\n        }\n        \n        # ... existing code to create move request ...\n    }\n    \n    # ... existing code ...\n}\n```\n\nAlso, add a study history database to track processed studies over time:\n\n```powershell\n# Function to initialize the study history database\nfunction Initialize-StudyHistoryDatabase {\n    $dbPath = Join-Path $global:cacheDirBasePath \"study-history.json\"\n    \n    if (-not (Test-Path $dbPath)) {\n        @{\n            \"ProcessedStudies\" = @{}\n            \"LastUpdated\" = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n        } | ConvertTo-Json | Set-Content -Path $dbPath\n        \n        Write-Log \"Initialized study history database at $dbPath\"\n    }\n    \n    return $dbPath\n}\n\n# Function to check if a study is in the history database\nfunction Is-StudyInHistory {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$StudyInstanceUID\n    )\n    \n    $dbPath = Initialize-StudyHistoryDatabase\n    $db = Get-Content -Path $dbPath | ConvertFrom-Json\n    \n    return $db.ProcessedStudies.PSObject.Properties.Name -contains $StudyInstanceUID\n}\n\n# Function to add a study to the history database\nfunction Add-StudyToHistory {\n    param(\n        [Parameter(Mandatory=$true)]\n        [string]$StudyInstanceUID,\n        \n        [Parameter(Mandatory=$true)]\n        [string]$PatientName,\n        \n        [Parameter(Mandatory=$true)]\n        [string]$StudyDate\n    )\n    \n    $dbPath = Initialize-StudyHistoryDatabase\n    $db = Get-Content -Path $dbPath | ConvertFrom-Json\n    \n    # Convert to a mutable object if needed\n    if ($null -eq $db.ProcessedStudies) {\n        $db.ProcessedStudies = @{}\n    } elseif ($db.ProcessedStudies -is [System.Management.Automation.PSCustomObject]) {\n        $processedStudies = @{}\n        foreach ($prop in $db.ProcessedStudies.PSObject.Properties) {\n            $processedStudies[$prop.Name] = $prop.Value\n        }\n        $db.ProcessedStudies = $processedStudies\n    }\n    \n    # Add the study to the database\n    $db.ProcessedStudies[$StudyInstanceUID] = @{\n        \"PatientName\" = $PatientName\n        \"StudyDate\" = $StudyDate\n        \"ProcessedAt\" = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    }\n    \n    $db.LastUpdated = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    \n    # Save the updated database\n    $db | ConvertTo-Json | Set-Content -Path $dbPath\n    \n    Write-Log \"Added study $StudyInstanceUID to history database\"\n}\n```\n\nUpdate the stage-3.ps1 script to add studies to the history database when they are successfully moved:\n\n```powershell\nfunction Process-MoveRequests {\n    # ... existing code ...\n    \n    foreach ($request in $moveRequests) {\n        # ... existing code ...\n        \n        if ($success) {\n            # ... existing code ...\n            \n            # Add the study to the history database\n            Add-StudyToHistory `\n                -StudyInstanceUID $studyUID `\n                -PatientName $studyInfo.PatientName `\n                -StudyDate $studyInfo.StudyDate\n        }\n        \n        # ... existing code ...\n    }\n    \n    # ... existing code ...\n}\n```",
        "testStrategy": "Test the deduplication functionality by attempting to process the same study multiple times. Verify that duplicate studies are correctly identified and skipped. Test the study history database by checking that studies are correctly added to the database and can be retrieved later.",
        "priority": "medium",
        "dependencies": [
          6,
          7
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Create Unit Tests",
        "description": "Develop a comprehensive set of unit tests for the QR Tool components.",
        "details": "Create a tests directory with the following test scripts:\n\n1. tests/Test-Utilities.ps1:\n```powershell\n# Import Pester module\nImport-Module Pester -ErrorAction Stop\n\n# Import the modules to test\n$projectRoot = Split-Path -Parent $PSScriptRoot\n. \"$projectRoot\\lib\\utility-funs.ps1\"\n\nDescribe \"Utility Functions\" {\n    Context \"Get-DicomTagsHash\" {\n        It \"Generates consistent hashes for the same input\" {\n            $hash1 = Get-DicomTagsHash -PatientName \"DOE^JOHN\" -PatientBirthDate \"19700101\" -StudyDate \"20230101\"\n            $hash2 = Get-DicomTagsHash -PatientName \"DOE^JOHN\" -PatientBirthDate \"19700101\" -StudyDate \"20230101\"\n            \n            $hash1 | Should -Be $hash2\n        }\n        \n        It \"Generates different hashes for different inputs\" {\n            $hash1 = Get-DicomTagsHash -PatientName \"DOE^JOHN\" -PatientBirthDate \"19700101\" -StudyDate \"20230101\"\n            $hash2 = Get-DicomTagsHash -PatientName \"SMITH^JANE\" -PatientBirthDate \"19800202\" -StudyDate \"20230202\"\n            \n            $hash1 | Should -Not -Be $hash2\n        }\n    }\n    \n    Context \"Ensure-DirectoryExists\" {\n        $testDir = \"$TestDrive\\test-dir\"\n        \n        It \"Creates a directory if it doesn't exist\" {\n            Ensure-DirectoryExists -Path $testDir\n            Test-Path $testDir | Should -Be $true\n        }\n        \n        It \"Doesn't throw an error if the directory already exists\" {\n            { Ensure-DirectoryExists -Path $testDir } | Should -Not -Throw\n        }\n    }\n    \n    # Add more tests for other utility functions\n}\n```\n\n2. tests/Test-DicomFunctions.ps1:\n```powershell\n# Import Pester module\nImport-Module Pester -ErrorAction Stop\n\n# Import the modules to test\n$projectRoot = Split-Path -Parent $PSScriptRoot\n. \"$projectRoot\\lib\\dicom-funs.ps1\"\n\nDescribe \"DICOM Functions\" {\n    Context \"Strip-DicomPixelData\" {\n        # This test requires a sample DICOM file\n        $sampleDicomFile = \"$TestDrive\\sample.dcm\"\n        $strippedDicomFile = \"$TestDrive\\stripped.dcm\"\n        \n        BeforeEach {\n            # Create a sample DICOM file or use a pre-existing one\n            # This is a placeholder - in a real test, you would need a valid DICOM file\n            if (-not (Test-Path $sampleDicomFile)) {\n                # Copy a sample DICOM file to the test directory\n                # Copy-Item -Path \"path\\to\\sample.dcm\" -Destination $sampleDicomFile\n                # For this example, we'll skip the test if no sample file is available\n                Set-ItResult -Skipped -Because \"No sample DICOM file available\"\n            }\n        }\n        \n        It \"Strips pixel data from a DICOM file\" -Skip {\n            $result = Strip-DicomPixelData -SourcePath $sampleDicomFile -DestinationPath $strippedDicomFile\n            \n            $result | Should -Be $true\n            Test-Path $strippedDicomFile | Should -Be $true\n            \n            # Verify that the pixel data has been removed\n            # This would require opening the DICOM file and checking for the absence of the pixel data tag\n        }\n    }\n    \n    # Add more tests for other DICOM functions\n}\n```\n\n3. tests/Test-Stages.ps1:\n```powershell\n# Import Pester module\nImport-Module Pester -ErrorAction Stop\n\n# Import the modules to test\n$projectRoot = Split-Path -Parent $PSScriptRoot\n. \"$projectRoot\\config.ps1\"\n. \"$projectRoot\\lib\\stage-1.ps1\"\n. \"$projectRoot\\lib\\stage-2.ps1\"\n. \"$projectRoot\\lib\\stage-3.ps1\"\n\nDescribe \"Stage 1: File Ingestion\" {\n    BeforeEach {\n        # Set up test environment\n        $global:cacheDirBasePath = \"$TestDrive\\cache\"\n        $global:incomingStoredItemsDirPath = \"$global:cacheDirBasePath\\incoming-stored-items\"\n        $global:queuedStoredItemsDirPath = \"$global:cacheDirBasePath\\queued-stored-items\"\n        $global:processedStoredItemsDirPath = \"$global:cacheDirBasePath\\processed-stored-items\"\n        $global:rejectedStoredItemsDirPath = \"$global:cacheDirBasePath\\rejected-stored-items\"\n        \n        # Create the directories\n        Ensure-DirectoryExists -Path $global:incomingStoredItemsDirPath\n        Ensure-DirectoryExists -Path $global:queuedStoredItemsDirPath\n        Ensure-DirectoryExists -Path $global:processedStoredItemsDirPath\n        Ensure-DirectoryExists -Path $global:rejectedStoredItemsDirPath\n        \n        # Set up test configuration\n        $global:mtimeThreshholdSeconds = 0\n        $global:largeFileThreshholdBytes = 1024\n        $global:rejectByDeleting = $false\n    }\n    \n    It \"Processes incoming files\" -Skip {\n        # This test would require sample DICOM files\n        # For this example, we'll skip the test\n        Set-ItResult -Skipped -Because \"No sample DICOM files available\"\n    }\n    \n    # Add more tests for Stage 1\n}\n\nDescribe \"Stage 2: Study Discovery\" {\n    # Similar setup and tests for Stage 2\n}\n\nDescribe \"Stage 3: Study Retrieval\" {\n    # Similar setup and tests for Stage 3\n}\n```\n\n4. Create a run-tests.ps1 script to run all tests:\n```powershell\n# Run all tests\nImport-Module Pester -ErrorAction Stop\n\n$testResults = Invoke-Pester -Path \"$PSScriptRoot\\tests\" -PassThru\n\nif ($testResults.FailedCount -gt 0) {\n    Write-Host \"$($testResults.FailedCount) tests failed.\" -ForegroundColor Red\n    exit 1\n} else {\n    Write-Host \"All tests passed!\" -ForegroundColor Green\n    exit 0\n}\n```",
        "testStrategy": "Run the unit tests using Pester and verify that they correctly test the functionality of the QR Tool components. Ensure that the tests cover both success and failure scenarios. Add more specific tests for edge cases and error conditions.",
        "priority": "low",
        "dependencies": [
          3,
          4,
          5,
          6,
          7,
          11,
          13
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Implement Periodic DICOM Modality Worklist Query",
        "description": "Develop a feature that periodically queries a DICOM Modality Worklist (MWL) endpoint at configurable intervals, detects new orders, tracks them in the system, and prefetches relevant patient images.",
        "details": "Create a new module in `lib/worklist-query.ps1` that implements the MWL query functionality:\n\n```powershell\n# Import required modules\n. \"$PSScriptRoot\\utility-funs.ps1\"\n. \"$PSScriptRoot\\dicom-funs.ps1\"\n. \"$PSScriptRoot\\logging.ps1\"\n. \"$PSScriptRoot\\retry.ps1\"\n\n# Function to query the DICOM Modality Worklist\nfunction Query-DicomWorklist {\n    param()\n    \n    Write-Log \"Querying DICOM Modality Worklist at $($global:WorklistEndpointHost):$($global:WorklistEndpointPort)\"\n    \n    try {\n        # Create DICOM C-FIND request for Modality Worklist\n        $request = New-DicomCFindRequest -QueryRetrieveLevel \"WORKLIST\"\n        \n        # Add relevant query attributes\n        $request.Add(0x00080005, \"ISO_IR 100\")  # Specific Character Set\n        $request.Add(0x00100010, \"\")            # Patient Name\n        $request.Add(0x00100020, \"\")            # Patient ID\n        $request.Add(0x00100030, \"\")            # Patient Birth Date\n        $request.Add(0x00100040, \"\")            # Patient Sex\n        $request.Add(0x0020000D, \"\")            # Study Instance UID\n        $request.Add(0x00080050, \"\")            # Accession Number\n        $request.Add(0x00400100, \"\")            # Scheduled Procedure Step Sequence\n        \n        # Execute the C-FIND request with retry mechanism\n        $worklistItems = Invoke-WithRetry -ScriptBlock {\n            Invoke-DicomCFind -Request $request -RemoteAE $global:WorklistEndpointAETitle -RemoteHost $global:WorklistEndpointHost -RemotePort $global:WorklistEndpointPort\n        } -MaxRetries 3 -RetryDelayMs 2000\n        \n        return $worklistItems\n    }\n    catch {\n        Write-LogError \"Error querying DICOM Modality Worklist: $_\"\n        return $null\n    }\n}\n\n# Function to compare worklist items with local cache and identify new orders\nfunction Get-NewWorklistItems {\n    param(\n        [Parameter(Mandatory=$true)]\n        [array]$WorklistItems\n    )\n    \n    # Ensure the worklist cache directory exists\n    $worklistCachePath = Join-Path $global:cacheDirPath \"worklist-cache\"\n    Ensure-DirectoryExists $worklistCachePath\n    \n    $newItems = @()\n    \n    foreach ($item in $WorklistItems) {\n        # Create a unique identifier for the worklist item (combination of Patient ID and Accession Number)\n        $patientId = $item.GetString(0x00100020)\n        $accessionNumber = $item.GetString(0x00080050)\n        $scheduledProcedureStepId = \"\"\n        \n        # Extract Scheduled Procedure Step ID from the Scheduled Procedure Step Sequence\n        $spsList = $item.GetSequence(0x00400100)\n        if ($spsList -and $spsList.Count -gt 0) {\n            $scheduledProcedureStepId = $spsList[0].GetString(0x00400009) # Scheduled Procedure Step ID\n        }\n        \n        $itemId = \"$patientId-$accessionNumber-$scheduledProcedureStepId\"\n        $itemCachePath = Join-Path $worklistCachePath \"$itemId.json\"\n        \n        # Check if this item is already in our cache\n        if (-not (Test-Path $itemCachePath)) {\n            # This is a new worklist item\n            $newItems += $item\n            \n            # Save the item to cache\n            $itemData = @{\n                \"PatientId\" = $patientId\n                \"PatientName\" = $item.GetString(0x00100010)\n                \"AccessionNumber\" = $accessionNumber\n                \"ScheduledProcedureStepId\" = $scheduledProcedureStepId\n                \"DiscoveryTime\" = (Get-Date).ToString(\"o\")\n            }\n            \n            $itemData | ConvertTo-Json | Set-Content -Path $itemCachePath\n        }\n    }\n    \n    return $newItems\n}\n\n# Function to create incoming-stored-item records for new worklist items\nfunction Create-IncomingStoredItems {\n    param(\n        [Parameter(Mandatory=$true)]\n        [array]$NewWorklistItems\n    )\n    \n    foreach ($item in $NewWorklistItems) {\n        $patientId = $item.GetString(0x00100020)\n        $patientName = $item.GetString(0x00100010)\n        $accessionNumber = $item.GetString(0x00080050)\n        $scheduledProcedureStepId = \"\"\n        \n        # Extract Scheduled Procedure Step ID from the Scheduled Procedure Step Sequence\n        $spsList = $item.GetSequence(0x00400100)\n        if ($spsList -and $spsList.Count -gt 0) {\n            $scheduledProcedureStepId = $spsList[0].GetString(0x00400009) # Scheduled Procedure Step ID\n        }\n        \n        # Create a unique filename for the incoming stored item\n        $timestamp = Get-Date -Format \"yyyyMMddHHmmss\"\n        $filename = \"worklist-$patientId-$accessionNumber-$timestamp.json\"\n        $filePath = Join-Path $global:incomingStoredItemsDirPath $filename\n        \n        # Create the incoming stored item record\n        $storedItem = @{\n            \"Source\" = \"WorklistQuery\"\n            \"PatientId\" = $patientId\n            \"PatientName\" = $patientName\n            \"AccessionNumber\" = $accessionNumber\n            \"ScheduledProcedureStepId\" = $scheduledProcedureStepId\n            \"DiscoveryTime\" = (Get-Date).ToString(\"o\")\n        }\n        \n        $storedItem | ConvertTo-Json | Set-Content -Path $filePath\n        Write-Log \"Created incoming stored item for worklist entry: $filename\"\n    }\n}\n\n# Function to prefetch patient images\nfunction Prefetch-PatientImages {\n    param(\n        [Parameter(Mandatory=$true)]\n        [array]$NewWorklistItems\n    )\n    \n    foreach ($item in $NewWorklistItems) {\n        $patientId = $item.GetString(0x00100020)\n        $patientName = $item.GetString(0x00100010)\n        \n        Write-Log \"Prefetching images for patient: $patientName (ID: $patientId)\"\n        \n        try {\n            # Query for patient's prior studies using QIDO-RS\n            $qidoUrl = \"$($global:QidoServiceUrl)/studies?PatientID=$patientId\"\n            $studies = Invoke-RestMethod -Uri $qidoUrl -Method Get -Headers @{ \"Accept\" = \"application/json\" }\n            \n            if ($studies -and $studies.Count -gt 0) {\n                Write-Log \"Found $($studies.Count) prior studies for patient $patientId\"\n                \n                # Apply filtering criteria\n                $filteredStudies = @()\n                foreach ($study in $studies) {\n                    $includeStudy = $true\n                    \n                    # Filter by date if configured\n                    if ($global:PrefetchFilterCriteria.daysPrior) {\n                        $studyDate = [DateTime]::ParseExact($study.\"00080020\".Value, \"yyyyMMdd\", $null)\n                        $cutoffDate = (Get-Date).AddDays(-$global:PrefetchFilterCriteria.daysPrior)\n                        \n                        if ($studyDate -lt $cutoffDate) {\n                            $includeStudy = $false\n                        }\n                    }\n                    \n                    # Filter by modality if configured\n                    if ($includeStudy -and $global:PrefetchFilterCriteria.modalities) {\n                        $studyModality = $study.\"00080060\".Value\n                        if ($studyModality -and -not ($global:PrefetchFilterCriteria.modalities -contains $studyModality)) {\n                            $includeStudy = $false\n                        }\n                    }\n                    \n                    if ($includeStudy) {\n                        $filteredStudies += $study\n                    }\n                }\n                \n                Write-Log \"$($filteredStudies.Count) studies match prefetch criteria for patient $patientId\"\n                \n                # Create prefetch cache directory for this patient\n                $patientPrefetchPath = Join-Path $global:PrefetchCachePath $patientId\n                Ensure-DirectoryExists $patientPrefetchPath\n                \n                # Retrieve each filtered study\n                foreach ($study in $filteredStudies) {\n                    $studyInstanceUid = $study.\"0020000D\".Value\n                    $studyPrefetchPath = Join-Path $patientPrefetchPath $studyInstanceUid\n                    Ensure-DirectoryExists $studyPrefetchPath\n                    \n                    # Get series for this study\n                    $seriesUrl = \"$($global:QidoServiceUrl)/studies/$studyInstanceUid/series\"\n                    $seriesList = Invoke-RestMethod -Uri $seriesUrl -Method Get -Headers @{ \"Accept\" = \"application/json\" }\n                    \n                    foreach ($series in $seriesList) {\n                        $seriesInstanceUid = $series.\"0020000E\".Value\n                        $seriesPrefetchPath = Join-Path $studyPrefetchPath $seriesInstanceUid\n                        Ensure-DirectoryExists $seriesPrefetchPath\n                        \n                        # Get instances for this series\n                        $instancesUrl = \"$($global:QidoServiceUrl)/studies/$studyInstanceUid/series/$seriesInstanceUid/instances\"\n                        $instances = Invoke-RestMethod -Uri $instancesUrl -Method Get -Headers @{ \"Accept\" = \"application/json\" }\n                        \n                        foreach ($instance in $instances) {\n                            $sopInstanceUid = $instance.\"00080018\".Value\n                            $instanceFilePath = Join-Path $seriesPrefetchPath \"$sopInstanceUid.dcm\"\n                            \n                            # Skip if already downloaded\n                            if (-not (Test-Path $instanceFilePath)) {\n                                # Retrieve the DICOM instance using WADO-RS\n                                $wadoUrl = \"$($global:WadoServiceUrl)/studies/$studyInstanceUid/series/$seriesInstanceUid/instances/$sopInstanceUid\"\n                                \n                                Invoke-WithRetry -ScriptBlock {\n                                    Invoke-WebRequest -Uri $wadoUrl -Method Get -Headers @{ \"Accept\" = \"application/dicom\" } -OutFile $instanceFilePath\n                                } -MaxRetries 3 -RetryDelayMs 2000\n                                \n                                Write-Log \"Downloaded instance $sopInstanceUid to $instanceFilePath\"\n                            }\n                        }\n                    }\n                }\n            }\n            else {\n                Write-Log \"No prior studies found for patient $patientId\"\n            }\n        }\n        catch {\n            Write-LogError \"Error prefetching images for patient $patientId: $_\"\n        }\n    }\n}\n\n# Main function to run the worklist query process\nfunction Start-WorklistQueryProcess {\n    Write-Log \"Starting Worklist Query Process\"\n    \n    # Query the worklist\n    $worklistItems = Query-DicomWorklist\n    \n    if ($worklistItems -and $worklistItems.Count -gt 0) {\n        Write-Log \"Retrieved $($worklistItems.Count) worklist items\"\n        \n        # Identify new worklist items\n        $newItems = Get-NewWorklistItems -WorklistItems $worklistItems\n        \n        if ($newItems -and $newItems.Count -gt 0) {\n            Write-Log \"Found $($newItems.Count) new worklist items\"\n            \n            # Create incoming stored items for tracking\n            Create-IncomingStoredItems -NewWorklistItems $newItems\n            \n            # Prefetch patient images\n            Prefetch-PatientImages -NewWorklistItems $newItems\n        }\n        else {\n            Write-Log \"No new worklist items found\"\n        }\n    }\n    else {\n        Write-Log \"No worklist items retrieved or error occurred\"\n    }\n}\n\n# Function to start the periodic worklist query\nfunction Start-PeriodicWorklistQuery {\n    Write-Log \"Starting periodic worklist query service\"\n    \n    while ($true) {\n        try {\n            Start-WorklistQueryProcess\n        }\n        catch {\n            Write-LogError \"Error in worklist query process: $_\"\n        }\n        \n        # Wait for the configured interval\n        Write-Log \"Waiting $($global:WorklistQueryIntervalSeconds) seconds until next worklist query\"\n        Start-Sleep -Seconds $global:WorklistQueryIntervalSeconds\n    }\n}\n```\n\nUpdate the `config.ps1` file to include the new configuration settings:\n\n```powershell\n# Worklist Query Configuration\n$global:WorklistEndpointAETitle = \"WORKLIST_SCP\"\n$global:WorklistEndpointHost = \"127.0.0.1\"\n$global:WorklistEndpointPort = 104\n$global:WorklistQueryIntervalSeconds = 300  # 5 minutes\n\n# QIDO/WADO Configuration\n$global:QidoServiceUrl = \"http://pacs.example.com/dicom-web\"\n$global:WadoServiceUrl = \"http://pacs.example.com/dicom-web\"\n$global:PrefetchCachePath = Join-Path $global:cacheDirPath \"prefetch-cache\"\n$global:PrefetchFilterCriteria = @{\n    \"daysPrior\" = 365\n    \"modalities\" = @(\"CT\", \"MR\")\n}\n```\n\nUpdate the main `qr-tool.ps1` script to include an option to start the worklist query service:\n\n```powershell\n# Add to the parameter block\nparam(\n    [Parameter(Mandatory=$false)]\n    [switch]$StartWorklistQuery\n)\n\n# Add to the main script\nif ($StartWorklistQuery) {\n    . \"$libPath\\worklist-query.ps1\"\n    Start-PeriodicWorklistQuery\n}\n```\n\nEnsure the prefetch cache directory exists:\n```powershell\n# Add to the directory creation section\nEnsure-DirectoryExists $global:PrefetchCachePath\n```",
        "testStrategy": "1. **Unit Testing**:\n   - Create mock DICOM worklist responses to test the `Query-DicomWorklist` function.\n   - Test the `Get-NewWorklistItems` function with both new and previously seen worklist items.\n   - Verify that `Create-IncomingStoredItems` correctly creates JSON files with the expected content.\n   - Test the filtering logic in `Prefetch-PatientImages` with various filter criteria.\n\n2. **Integration Testing**:\n   - Configure the tool to connect to a test DICOM worklist provider.\n   - Verify that new worklist items are correctly detected across multiple query intervals.\n   - Confirm that incoming stored items are created with the correct metadata.\n   - Test the QIDO-RS and WADO-RS integration by verifying that studies are correctly queried and retrieved.\n\n3. **Performance Testing**:\n   - Test with a large worklist to ensure efficient processing.\n   - Verify that the prefetch mechanism doesn't overwhelm system resources.\n   - Test with different query intervals to ensure the system can handle frequent queries.\n\n4. **Configuration Testing**:\n   - Test with various configuration settings to ensure the tool adapts correctly.\n   - Verify that changes to filter criteria correctly affect which studies are prefetched.\n   - Test with invalid configuration to ensure proper error handling.\n\n5. **End-to-End Testing**:\n   - Run a complete workflow from worklist query to image prefetching.\n   - Verify that all components work together correctly.\n   - Confirm that the periodic nature of the query works as expected over extended periods.\n\n6. **Error Handling Testing**:\n   - Simulate network failures during DICOM worklist queries.\n   - Test behavior when QIDO-RS or WADO-RS services are unavailable.\n   - Verify that the service continues to function after encountering errors.",
        "status": "pending",
        "dependencies": [
          4,
          11,
          13
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Core Worklist Query Functionality",
            "description": "Implement the fundamental DICOM Modality Worklist (MWL) query functionality to retrieve scheduled procedures from PACS/RIS systems.",
            "dependencies": [],
            "details": "Develop the core query mechanism that constructs and sends DICOM C-FIND requests to the configured MWL SCP. Include proper DICOM dataset construction with query parameters (PatientID, AccessionNumber, etc.), network connection handling, response parsing, and error handling. Implement configurable query filters and result mapping to internal data structures.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Worklist Cache System",
            "description": "Create a caching mechanism to track previously seen worklist items and avoid duplicate processing.",
            "dependencies": [
              1
            ],
            "details": "Design and implement a persistent cache store that maintains records of previously processed worklist items. Include functionality to store unique identifiers (AccessionNumber, StudyInstanceUID), timestamp information, and processing status. Implement methods to query, update, and prune the cache. Ensure thread-safety for concurrent access and develop a strategy for cache invalidation.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Develop Incoming Stored Item Creation Process",
            "description": "Create the process for generating and storing new items based on worklist query results.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement the logic to transform DICOM worklist entries into application-specific stored items. Include validation of required fields, normalization of data formats, and proper error handling for malformed entries. Develop the database operations for persisting these items and implement the workflow to mark items as processed in the cache system.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Build Patient Image Prefetching System",
            "description": "Implement the system to prefetch relevant patient images using QIDO/WADO RESTful services.",
            "dependencies": [
              3
            ],
            "details": "Create the prefetching mechanism that uses QIDO-RS to query for existing studies/series/instances related to patients in the worklist. Implement WADO-RS requests to retrieve the actual image data. Develop intelligent filtering to prioritize relevant prior studies. Include configurable limits on prefetch volume and implement background downloading with proper resource management. Add error recovery for failed retrievals.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Implement Periodic Query Service",
            "description": "Create a service that periodically executes worklist queries according to configurable schedules.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Develop a long-running service architecture that executes worklist queries at configurable intervals. Implement proper scheduling with configurable frequency and time windows. Include logging of query execution, results, and errors. Develop monitoring capabilities to track service health. Implement graceful shutdown and recovery mechanisms for service interruptions.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Integrate with Main Application",
            "description": "Connect the DICOM Modality Worklist system with the main application's workflow and UI.",
            "dependencies": [
              3,
              4,
              5
            ],
            "details": "Integrate the worklist query system with the application's main workflow. Implement UI components to display worklist items, prefetched studies, and query status. Add configuration interfaces for worklist sources, query parameters, and scheduling. Develop notification mechanisms for new items and prefetch completion. Implement user-triggered manual queries and ensure proper error reporting to users.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-06-27T17:35:22.715Z",
      "updated": "2025-06-27T17:57:57.882Z",
      "description": "Tasks for master context"
    }
  }
}